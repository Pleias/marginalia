{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSHlAbqzDFDq"
      },
      "source": [
        "# Demo marginalia\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/Pleias/marginalia/main/notebook/marginalia_logo.jpg\" style=\"float:right;\" alt=\"marginalia logo\" width=\"300\"/>\n",
        "\n",
        "\n",
        "This code notebook provides an initial demo of marginalia, a lightweight application to retrieve corpus annotations with open LLM like Mistral OpenHermes 2.5.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "marginalia is for now only available on Github:"
      ],
      "metadata": {
        "id": "Np-mT9s-avqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install git+https://github.com/Pleias/marginalia.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPO0vtKEKtaU",
        "outputId": "b48b197a-168f-42a0-befe-60140a52745c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/Pleias/marginalia.git\n",
            "  Cloning https://github.com/Pleias/marginalia.git to /tmp/pip-req-build-rib_5bn7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Pleias/marginalia.git /tmp/pip-req-build-rib_5bn7\n",
            "  Resolved https://github.com/Pleias/marginalia.git to commit 84984bccf93016e26aafd65624d17ac7c79c02d1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: marginalia\n",
            "  Building wheel for marginalia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for marginalia: filename=marginalia-0.1.0-py3-none-any.whl size=3709 sha256=65cc4807d32355d68740b7fd355f4c403a3c1bcc2bfd13616b4924e0f218c708\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pyuldqtb/wheels/32/db/49/703181bf805653e03da51802e4481682d35cb87276ab0493b3\n",
            "Successfully built marginalia\n",
            "Installing collected packages: marginalia\n",
            "Successfully installed marginalia-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparation of the data"
      ],
      "metadata": {
        "id": "z9Mz-u4t2g-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "marginalia works with any list of unstructured texts. It will generate id on the fly simply based on the index of the text, as well as return the unprocessed text as part of the json output."
      ],
      "metadata": {
        "id": "QgQ6SyLP2n48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to test marginalia on a set of 445 individual titles recommended by no other than Benjamin Franklin (*A catalogue of choice and valuable books, consisting of near 600 volumes*)"
      ],
      "metadata": {
        "id": "5wGYYbQuZxO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "unstructured = pd.read_csv(\"https://raw.githubusercontent.com/Pleias/marginalia/main/notebook/franklin_library.tsv\", sep = \"\\t\")[\"text\"].tolist()"
      ],
      "metadata": {
        "id": "XoOkN2eW2j4k"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's have the look at the first titles"
      ],
      "metadata": {
        "id": "YpQlp4XXaV8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unstructured[0:10]"
      ],
      "metadata": {
        "id": "ExDJcctit39d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c177fcd-12c0-4d53-f5ca-ef6c59ae111b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1 FINE large Folio BIBLE, compleat, Oxford 1727.',\n",
              " '2 Ditto, with Maps, Notes, &c.',\n",
              " \"3 Clarendon's History of the Rebellion, 3 Vols\",\n",
              " \"4 Bayley's universal etimologlcal Dictionary.\",\n",
              " '5 Marlorati Thesaurus Scripturae.',\n",
              " \"6 Wiquefort's compleat Ambassador, translated by Digby, finely bound.\",\n",
              " \"7 Hobbes's Leviathan, very scarce.\",\n",
              " \"8 R. Barclay's Works, compleat.\",\n",
              " \"9 D. Rogers's Lectures on Naaman the Syrian.\",\n",
              " \"10 Bunny's Head Corner-Stone.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "marginalia aims to recover a *data scheme*. To create the scheme, you simply initiate a dictionary with fields and their definition. Basically, you want to apply the data scheme to your unstructured set of text everytime fits."
      ],
      "metadata": {
        "id": "Tyuneqr8cjb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_scheme = {\"author\": \"the author(s) of the book, which can be expressed with a possessive like Hobbe's\",\n",
        "               \"title\": \"the title of the book\",\n",
        "               \"translator\": \"the translator(s) of the book\",\n",
        "               \"date\": \"the date of publication\",\n",
        "               \"place\": \"the place of publication\",\n",
        "               \"format\": \"any information related to the format such as volumes, folios\",\n",
        "               \"other\": \"any other information related to the book\"}"
      ],
      "metadata": {
        "id": "zvkgakgpcoT7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The core of marginalia functionality is instruction_set. That's where you are going to pass the unstructured text, the data scheme and the prompt instructions."
      ],
      "metadata": {
        "id": "P0IEgLvWa24u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from marginalia import instruction_set\n",
        "\n",
        "instructions = instruction_set(data_scheme = data_scheme,\n",
        "                               unstructured = unstructured,\n",
        "                               system_prompt = \"You are a powerful annotator of bibliographic data\",\n",
        "                               input_prompt = \"Transform this list of book entries into structured bibliographic data\",\n",
        "                               definition_prompt = \"Extract the following bibliographic fields:\",\n",
        "                               structure_prompt = \"Return the results as a json structured like this :\",\n",
        "                               data_prompt = \"Here is the list of books :\",\n",
        "                               name_id = \"book\",\n",
        "                               size_batch = 10)"
      ],
      "metadata": {
        "id": "YPtFBcWPLF2w"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can notice the prompt as six parts:\n",
        "\n",
        "* System prompt: basically defining what kind of the tool LLM is, in a very broad way.\n",
        "* Input prompt: the actual task at hand.\n",
        "* Definition prompt: the introductory prompt for the list of definitions stored in the data scheme.\n",
        "* Structure prompt: the introductory prompt for an empty sample of the json structure.\n",
        "* Data prompt: the introductory prompt for the list of unstructured text sample.\n",
        "* Name id: the name used to qualify each unstructured text sample\n",
        "\n",
        "Additionally you can define the size of the batch with a size_batch. Overall the longer your text sample are, the smaller your batch should be to not overload the context window."
      ],
      "metadata": {
        "id": "fxkG5R3_a9Vy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before launching the actual LLM-powered annotation, it is advisable to give a look the data and check if everything is fine. You can do it with test_prompt:"
      ],
      "metadata": {
        "id": "1521sQc0Zfpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instructions.test_prompt()"
      ],
      "metadata": {
        "id": "zlcW1qxHN3Pp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And the return the first prompt:"
      ],
      "metadata": {
        "id": "M9RZ55acZhpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(instructions.prompts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXZXOABhaj2D",
        "outputId": "be3316cc-7e0b-404f-c2a9-8e53ecbb716b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>system\n",
            "You are a powerful annotator of bibliographic data\n",
            "<|im_end|>\n",
            "<|im_start|>user\n",
            "Transform this list of book entries into structured bibliographic data\n",
            "\n",
            "Extract the following bibliographic fields: the book id (\"id\"), the author(s) of the book, which can be expressed with a possessive like Hobbe's (\"author\"), the title of the book (\"title\"), the translator(s) of the book (\"translator\"), the date of publication (\"date\"), the place of publication (\"place\"), any information related to the format such as volumes, folios (\"format\"), any other information related to the book (\"other\")\n",
            "\n",
            "Return the results as a json structured like this : {\"id\": \"…\", \"author\": \"…\", \"title\": \"…\", \"translator\": \"…\", \"date\": \"…\", \"place\": \"…\", \"format\": \"…\", \"other\": \"…\"}\n",
            "\n",
            "Here is the list of books :\n",
            "\n",
            "book 0: 1 FINE large Folio BIBLE, compleat, Oxford 1727.\n",
            "\n",
            "book 1: 2 Ditto, with Maps, Notes, &c.\n",
            "\n",
            "book 2: 3 Clarendon's History of the Rebellion, 3 Vols\n",
            "\n",
            "book 3: 4 Bayley's universal etimologlcal Dictionary.\n",
            "\n",
            "book 4: 5 Marlorati Thesaurus Scripturae.\n",
            "\n",
            "book 5: 6 Wiquefort's compleat Ambassador, translated by Digby, finely bound.\n",
            "\n",
            "book 6: 7 Hobbes's Leviathan, very scarce.\n",
            "\n",
            "book 7: 8 R. Barclay's Works, compleat.\n",
            "\n",
            "book 8: 9 D. Rogers's Lectures on Naaman the Syrian.\n",
            "\n",
            "book 9: 10 Bunny's Head Corner-Stone.\n",
            "\n",
            "<|im_end|>\n",
            "<|im_start|> assistant\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsHIuzqQpa3A"
      },
      "source": [
        "## Loading the model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then to use the LLM, you need to load it with vllm. This notebook provide a tested solution for Google Colab but do not hesitate to check the vllm documentation:"
      ],
      "metadata": {
        "id": "ZHnjOCNtDmRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lmdb\n",
        "!pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2 torchtext==0.15.2+cpu torchdata==0.6.1 --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install transformers\n",
        "!pip install vllm"
      ],
      "metadata": {
        "id": "VWLOMJd_7Jyu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e274de40-0be7-40f9-8ee2-37cb947f8599"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lmdb\n",
            "  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lmdb\n",
            "Successfully installed lmdb-1.4.1\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.0.1+cu118\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp310-cp310-linux_x86_64.whl (2267.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m832.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.15.2+cu118\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp310-cp310-linux_x86_64.whl (6.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.0.2\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.0.2%2Bcu118-cp310-cp310-linux_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m517.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchtext==0.15.2+cpu\n",
            "  Downloading https://download.pytorch.org/whl/torchtext-0.15.2%2Bcpu-cp310-cp310-linux_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchdata==0.6.1\n",
            "  Downloading https://download.pytorch.org/whl/torchdata-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1+cu118) (3.1.3)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2+cu118) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2+cu118) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2+cu118) (9.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2+cpu) (4.66.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.1) (2.0.7)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1+cu118) (3.27.9)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1+cu118)\n",
            "  Downloading https://download.pytorch.org/whl/lit-15.0.7.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1+cu118) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2+cu118) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2+cu118) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2+cu118) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1+cu118) (1.3.0)\n",
            "Building wheels for collected packages: lit\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-15.0.7-py3-none-any.whl size=89990 sha256=19de07a8afd60e91cb20d7a5dc7364c2487a04816f99350385b305b6f18f727f\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/2c/b6/3ed2983b1b44fe0dea1bb35234b09f2c22fb8ebb308679c922\n",
            "Successfully built lit\n",
            "Installing collected packages: lit, triton, torch, torchdata, torchvision, torchtext, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "  Attempting uninstall: torchdata\n",
            "    Found existing installation: torchdata 0.7.0\n",
            "    Uninstalling torchdata-0.7.0:\n",
            "      Successfully uninstalled torchdata-0.7.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.16.0+cu121\n",
            "    Uninstalling torchvision-0.16.0+cu121:\n",
            "      Successfully uninstalled torchvision-0.16.0+cu121\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.16.0\n",
            "    Uninstalling torchtext-0.16.0:\n",
            "      Successfully uninstalled torchtext-0.16.0\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.1.0+cu121\n",
            "    Uninstalling torchaudio-2.1.0+cu121:\n",
            "      Successfully uninstalled torchaudio-2.1.0+cu121\n",
            "Successfully installed lit-15.0.7 torch-2.0.1+cu118 torchaudio-2.0.2+cu118 torchdata-0.6.1 torchtext-0.15.2+cpu torchvision-0.15.2+cu118 triton-2.0.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Collecting vllm\n",
            "  Downloading vllm-0.3.0-cp310-cp310-manylinux1_x86_64.whl (38.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from vllm)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from vllm) (5.9.5)\n",
            "Collecting ray>=2.9 (from vllm)\n",
            "  Downloading ray-2.9.2-cp310-cp310-manylinux2014_x86_64.whl (64.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from vllm) (0.1.99)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vllm) (1.23.5)\n",
            "Collecting torch==2.1.2 (from vllm)\n",
            "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers>=4.37.0 (from vllm)\n",
            "  Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xformers==0.0.23.post1 (from vllm)\n",
            "  Downloading xformers-0.0.23.post1-cp310-cp310-manylinux2014_x86_64.whl (213.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi (from vllm)\n",
            "  Downloading fastapi-0.109.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard] (from vllm)\n",
            "  Downloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.6.1)\n",
            "Collecting aioprometheus[starlette] (from vllm)\n",
            "  Downloading aioprometheus-23.12.0-py3-none-any.whl (31 kB)\n",
            "Collecting pynvml==11.5.0 (from vllm)\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.1.0 (from torch==2.1.2->vllm)\n",
            "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->vllm)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->vllm) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->vllm) (2.16.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (8.1.7)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (23.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (6.0.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (2.31.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.0->vllm) (0.20.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.0->vllm) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.0->vllm) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.0->vllm) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.0->vllm) (4.66.1)\n",
            "Collecting orjson (from aioprometheus[starlette]->vllm)\n",
            "  Downloading orjson-3.9.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting quantile-python>=1.1 (from aioprometheus[starlette]->vllm)\n",
            "  Downloading quantile-python-1.1.tar.gz (2.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting starlette>=0.14.2 (from aioprometheus[starlette]->vllm)\n",
            "  Downloading starlette-0.37.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11>=0.8 (from uvicorn[standard]->vllm)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]->vllm)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]->vllm)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->vllm)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]->vllm)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]->vllm)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette>=0.14.2->aioprometheus[starlette]->vllm) (3.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.2->vllm) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.9->vllm) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.9->vllm) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.9->vllm) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.9->vllm) (0.17.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray>=2.9->vllm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray>=2.9->vllm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray>=2.9->vllm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray>=2.9->vllm) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.2->vllm) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.14.2->aioprometheus[starlette]->vllm) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.14.2->aioprometheus[starlette]->vllm) (1.2.0)\n",
            "Building wheels for collected packages: quantile-python\n",
            "  Building wheel for quantile-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for quantile-python: filename=quantile_python-1.1-py3-none-any.whl size=3444 sha256=bd92e0949ea90fcc3d79704733f5f29a6d0ef688415fad383688c6adda1e2c71\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/f4/0a/0e7d01548a005f9f3fa23101f071d248da052f2a9bf2fe11c6\n",
            "Successfully built quantile-python\n",
            "Installing collected packages: quantile-python, ninja, websockets, uvloop, triton, python-dotenv, pynvml, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, httptools, h11, watchfiles, uvicorn, starlette, nvidia-cusparse-cu12, nvidia-cudnn-cu12, aioprometheus, nvidia-cusolver-cu12, fastapi, transformers, torch, ray, xformers, vllm\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.0.0\n",
            "    Uninstalling triton-2.0.0:\n",
            "      Successfully uninstalled triton-2.0.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 2.1.2 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 2.1.2 which is incompatible.\n",
            "torchtext 0.15.2+cpu requires torch==2.0.1, but you have torch 2.1.2 which is incompatible.\n",
            "torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aioprometheus-23.12.0 fastapi-0.109.2 h11-0.14.0 httptools-0.6.1 ninja-1.11.1.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 orjson-3.9.13 pynvml-11.5.0 python-dotenv-1.0.1 quantile-python-1.1 ray-2.9.2 starlette-0.36.3 torch-2.1.2 transformers-4.37.2 triton-2.1.0 uvicorn-0.27.1 uvloop-0.19.0 vllm-0.3.0 watchfiles-0.21.0 websockets-12.0 xformers-0.0.23.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import LLM, SamplingParams\n",
        "import os"
      ],
      "metadata": {
        "id": "YtBDal4b_ZBo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = LLM(\"teknium/OpenHermes-2.5-Mistral-7B\")"
      ],
      "metadata": {
        "id": "RqQSYyoFIoqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampling_params = SamplingParams(temperature=0.7, top_p=0.95, max_tokens=8000, presence_penalty = 0)"
      ],
      "metadata": {
        "id": "62R-8MCaKPPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate the annotations"
      ],
      "metadata": {
        "id": "Rb5FUOPObW0f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point, the actual annotation is one command. You'll notice that marginalia does several pass on vllm to send again any non-compliant json."
      ],
      "metadata": {
        "id": "r60DLcJEZCQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instructions.llm_generate_loop(llm, sampling_params)"
      ],
      "metadata": {
        "id": "LaFUVuZBL_ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By the end of this process you can check your json:"
      ],
      "metadata": {
        "id": "ZY-wq-y-ZH3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instructions.valid_json[0:6]"
      ],
      "metadata": {
        "id": "4WGCVj-EqUNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "760ae317-305b-43d6-d39d-cef780d63ba1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 0,\n",
              "  'author': None,\n",
              "  'title': 'FINE large Folio BIBLE',\n",
              "  'translator': None,\n",
              "  'date': '1727',\n",
              "  'place': 'Oxford',\n",
              "  'format': 'compleat',\n",
              "  'other': None,\n",
              "  'original_source': 'FINE large Folio BIBLE, compleat, Oxford 1727.'},\n",
              " {'id': 1,\n",
              "  'author': '',\n",
              "  'title': 'Ditto, with Maps, Notes, &c.',\n",
              "  'translator': '',\n",
              "  'date': '',\n",
              "  'place': '',\n",
              "  'format': '',\n",
              "  'other': '',\n",
              "  'original_source': 'Ditto, with Maps, Notes, &c.'},\n",
              " {'id': 2,\n",
              "  'author': 'Clarendon',\n",
              "  'title': 'History of the Rebellion',\n",
              "  'translator': '',\n",
              "  'date': '1727',\n",
              "  'place': 'Oxford',\n",
              "  'format': '3 Vols',\n",
              "  'other': '',\n",
              "  'original_source': \"Clarendon's History of the Rebellion, 3 Vols\"},\n",
              " {'id': 3,\n",
              "  'author': 'Bayley',\n",
              "  'title': 'universal etimologlcal Dictionary',\n",
              "  'translator': '',\n",
              "  'date': '1727',\n",
              "  'place': 'Oxford',\n",
              "  'format': '',\n",
              "  'other': '',\n",
              "  'original_source': \"Bayley's universal etimologlcal Dictionary.\"},\n",
              " {'id': 4,\n",
              "  'author': 'Marlorati',\n",
              "  'title': 'Thesaurus Scripturae',\n",
              "  'translator': '',\n",
              "  'date': '1727',\n",
              "  'place': 'Oxford',\n",
              "  'format': '',\n",
              "  'other': '',\n",
              "  'original_source': 'Marlorati Thesaurus Scripturae.'},\n",
              " {'id': 5,\n",
              "  'author': 'Wiquefort',\n",
              "  'title': 'compleat Ambassador',\n",
              "  'translator': 'Digby',\n",
              "  'date': '1727',\n",
              "  'place': 'Oxford',\n",
              "  'format': '',\n",
              "  'other': 'finely bound',\n",
              "  'original_source': \"Wiquefort's compleat Ambassador, translated by Digby, finely bound.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}